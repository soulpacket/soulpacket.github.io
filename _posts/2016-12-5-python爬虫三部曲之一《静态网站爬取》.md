---
layout:		post
title: 		"python爬虫三部曲之一《静态网站爬取》"
subtitle :	"requests+xpath是极好的"
date: 		2016-12-5 17:31:59
author: 	"Mr. freedom"
header-img: 	"/img/post-bg-2015.jpg"
tags:
        - python
        - 爬虫 
---

>这是我发布的第一篇文章，借blog来记录自己的一些心得体会。以实战为主，废话不多说，直接开搞。

## 原理
* 爬虫通过python模块***requests***内置的*get*方法请求服务器，会返回一个`reponse`对象，里面包含了服务器响应的所有信息，我们需要的往往就是这些信息。[详细用法见requests官方文档](http://docs.python-requests.org/en/master/)
* 得到了信息之后呢，当然是抓取我们关心的关键字。这里我喜欢用python的正则表达式`re`模块和`xpath`，原因：简单好用，谁用谁知道！

## 准备工作
* python3.5
* 安装***lxml***模块,python3不可以简单的用```pip install lxml```,会报错。mac下需要这样:

		brew install libxml2     
		brew install libxslt     
		brew link libxml2 --force
		brew link libxslt --force
		STATIC_DEPS=true pip install lxml
		
	or

		xcode-select --install
		
	windows下参考[这位朋友的博文](https://www.polarxiong.com/archives/Python3-4-3-x64-%E4%B8%8B%E5%AE%89%E8%A3%85lxml-%E4%B8%8D%E9%9C%80%E8%A6%81%E7%BC%96%E8%AF%91%E5%99%A8%E4%BE%9D%E8%B5%96.html)

* 安装requests

		pip install requests
* 想学习下正则表达式的话，可以安装***re***模块(做过[pythonchallenge](http://www.pythonchallenge.com/)的同学会知道正则表达式的威力)

## 实战
>未完待续







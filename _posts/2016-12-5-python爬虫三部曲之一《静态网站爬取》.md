---
layout:		post
title: 		"python爬虫三部曲之一《静态网站爬取》"
subtitle :	"requests+xpath是极好的"
date: 		2016-12-5 17:31:59
author: 	"Mr. freedom"
header-img: 	"/img/post-bg-2015.jpg"
tags:
        - python
        - 爬虫 
---

>这是我发布的第一篇文章，借blog来记录自己的一些心得体会。以实战为主，废话不多说，直接开搞。

## 原理
* 爬虫通过python模块***requests***内置的*get*方法请求服务器，会返回一个`reponse`对象，里面包含了服务器响应的所有信息，我们需要的往往就是这些信息。[详细用法见requests官方文档](http://docs.python-requests.org/en/master/)
* 得到了信息之后呢，当然是抓取我们关心的关键字。这里我喜欢用python的正则表达式`re`模块和`xpath`，原因：简单好用，谁用谁知道！

## 准备工作
* python3.5
* 安装***lxml***模块,python3不可以简单的用```pip install lxml```,会报错。mac下需要这样:

		brew install libxml2     
		brew install libxslt     
		brew link libxml2 --force
		brew link libxslt --force
		STATIC_DEPS=true pip install lxml
	
	or
		
		xcode-select --install
		
	windows下参考[这位朋友的博文](https://www.polarxiong.com/archives/Python3-4-3-x64-%E4%B8%8B%E5%AE%89%E8%A3%85lxml-   %E4%B8%8D%E9%9C%80%E8%A6%81%E7%BC%96%E8%AF%91%E5%99%A8%E4%BE%9D%E8%B5%96.html)

* 安装requests

		pip install requests
* 想学习下正则表达式的话，可以安装***re***模块(做过[pythonchallenge](http://www.pythonchallenge.com/)的同学会知道正则表达式的威力)

## 实战
  我们就以天猫超市为例，想抓取页面上的某个商品名称
 		url='https://list.tmall.com/search_product.htm?q=%E9%9B%B6%E9%A3%9F&click_id=%C1%E3%CA%B3&from=mallfp..pc_1.1_hq&spm=875.7931836%2FB.a1z5h.2.8ZPlJT'
  			
  我们先用get方法得到服务器返回的html：
  
```python
import requests
import re
from lxml import etree
r = requests.get(url)
print(r.text)	
```

```python
import requests
import re
from lxml import etree
r = requests.get(url)
print(r.text)	
```
 
  截取其中一部分的文本
  
```
<a href="//detail.tmall.com/item.htm?
id=524140012885&amp;skuId=461168654256400789&amp;
user_id=2453719882&amp;cat_id=2&amp;is_b=1&amp;rn=
80dfcb54ea
e20a3112d72a082680d48b" target="_blank" title="
GENUOVA马卡龙甜点礼盒装24枚手工法式甜点送礼派对糕
点西式零食" data-p="31-11" >
```
  
  把零食的名字拿下来
  
  * 正则表达式

```python
w = re.findall('blank" title="(.*?)" data',a.text,re.S)
```
 
  	得到
  	
`GENUOVA马卡龙甜点礼盒装24枚手工法式甜点送礼派对糕点西式零食`
  	
  * xpath

```python
selector = etree.HTML(a.text)
content = selector.xpath('//*[@id="J_ItemList"]/div[22]/div/div[2]/a/text()')
```
 
>注意这里xpath地址需要你自己去拿。

>小tip:chrome和Mozilla Firefox都提供开发者工具，右击网页“检查”，锁定你要的地方，可以在代码处右击“copy xpath”。

看到这会不会有个疑问，get请求服务器会耗费资源，当你循环的请求网站资源时，会不会把网站跑废了？答案是会的！爬虫高频率的请求资源，会阻碍正常用户的访问(这不就是DDoS嘛)，所以在对待一些小网站，要礼貌性的设置一些爬虫get的时间间隔。

那网站为了防止这种情况发生会部署一些反爬虫措施。第三篇文章主要讲突破这些措施。

下一篇会涉及到***动态爬取***,***模拟登录***,***模拟搜索***。

  
  

  
  
  
  






